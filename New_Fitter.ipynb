{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process class estimation of percentage job complete is inverse!\n",
    "It should be ``where(completed == 1)`` not ``where(completed == 0)``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Suhas\\PycharmProjects\\pyUSID')\n",
    "sys.path.append(r'C:\\Users\\Suhas\\PycharmProjects\\pycroscopy')\n",
    "import os\n",
    "import h5py\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pyUSID as usid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from be_sho_fitter import BESHOfitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_data_path = r'C:\\Users\\Suhas\\PycharmProjects\\pyUSID\\data\\BEPS_small.h5'\n",
    "temp_dir = r'C:\\Users\\Suhas\\Desktop\\BESHOFitter_Testing'\n",
    "#if os.path.exists(temp_dir):\n",
    "#    os.remove(temp_dir)\n",
    "#os.mkdir(temp_dir)\n",
    "input_data_path = shutil.copy(orig_data_path, os.path.join(temp_dir, 'BEPS_small.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data_path = r'C:\\Users\\Suhas\\Desktop\\BESHOFitter_Testing\\BELine_0004.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 dataset \"Raw_Data\": shape (25, 22272), type \"<c8\">\n"
     ]
    }
   ],
   "source": [
    "h5_f = h5py.File(input_data_path, mode='r+')\n",
    "h5_main = h5_f['Measurement_000/Channel_000/Raw_Data']\n",
    "print(h5_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "├ Measurement_000\n",
      "  ---------------\n",
      "  ├ Channel_000\n",
      "    -----------\n",
      "    ├ Bin_FFT\n",
      "    ├ Bin_Frequencies\n",
      "    ├ Bin_Indices\n",
      "    ├ Bin_Step\n",
      "    ├ Bin_Wfm_Type\n",
      "    ├ Excitation_Waveform\n",
      "    ├ Noise_Floor\n",
      "    ├ Position_Indices\n",
      "    ├ Position_Values\n",
      "    ├ Raw_Data\n",
      "    ├ Raw_Data-SHO_Fit_000\n",
      "      --------------------\n",
      "      ├ Fit\n",
      "      ├ Guess\n",
      "      ├ Spectroscopic_Indices\n",
      "      ├ Spectroscopic_Values\n",
      "    ├ Spatially_Averaged_Plot_Group_000\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spatially_Averaged_Plot_Group_001\n",
      "      ---------------------------------\n",
      "      ├ Bin_Frequencies\n",
      "      ├ Mean_Spectrogram\n",
      "      ├ Spectroscopic_Parameter\n",
      "      ├ Step_Averaged_Response\n",
      "    ├ Spectroscopic_Indices\n",
      "    ├ Spectroscopic_Values\n",
      "    ├ UDVS\n",
      "    ├ UDVS_Indices\n"
     ]
    }
   ],
   "source": [
    "usid.hdf_utils.print_tree(h5_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mpi4py found or script was not called via mpixexec / mpirun. Assuming single node computation\n",
      "Rank 0 - on socket with 4 logical cores and 1.24 GB avail. RAM shared by 1 ranks each given 3 cores.\n",
      "Allowed to read 2498 pixels per chunk\n",
      "Consider calling test() to check results before calling compute() which computes on the entire dataset and writes back to the HDF5 file\n",
      "Checking for duplicates:\n",
      "Groups with Guess in:\n",
      "Completed: []\n",
      "Partial:[]\n",
      "Creating HDF5 group and datasets to hold results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\PycharmProjects\\pyUSID\\pyUSID\\io\\usi_data.py:148: UserWarning: This dataset does not have an N-dimensional form\n",
      "  warn('This dataset does not have an N-dimensional form')\n",
      "C:\\Users\\Suhas\\PycharmProjects\\pyUSID\\pyUSID\\io\\hdf_utils\\simple.py:1074: FutureWarning: write_reduced_spec_dsets is deprecated. Please use write_reduced_anc_dsets instead\n",
      "  warn('write_reduced_spec_dsets is deprecated. Please use write_reduced_anc_dsets instead', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h5 group and file OK\n",
      "quantity, units, main_data_name all OK\n",
      "Selected empty dataset creation. OK so far\n",
      "Provided h5 position indices and values OK\n",
      "Provided h5 spectroscopic datasets were OK\n",
      "Created empty dataset for Main\n",
      "Wrote quantity and units attributes to main dataset\n",
      "Wrote provided attributes to main dataset\n",
      "Successfully linked datasets - dataset should be main now\n",
      "Finished creating Guess dataset\n",
      "Creating the status dataset now\n",
      "Completed positions: 0\n",
      "Completed positions: 0\n",
      "Among the 25 positions in this dataset, the following positions need to be computed: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24].\n",
      "Each rank is required to work on 25 of the 25 (remaining) positions in this dataset.\n",
      "Rank 0 will read positions 0 to 25 of 25\n",
      "\tThis class (likely) supports interruption and resuming of computations!\n",
      "\tIf you are operating in a python console, press Ctrl+C or Cmd+C to abort\n",
      "\tIf you are in a Jupyter notebook, click on \"Kernel\">>\"Interrupt\"\n",
      "\tIf you are operating on a cluster and your job gets killed, re-run the job to resume\n",
      "\n",
      "Rank: 0 - with nothing loaded has 1.23 GB free memory\n",
      "Rank 0 - Read positions: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "Got raw data of shape (25, 22272) from super\n",
      "Reshaped raw data to shape (6400, 87)\n",
      "Rank: 0 - with only raw data loaded has 1.23 GB free memory\n",
      "Number of CPU free cores set to: 1 given that the CPU has 4 logical cores.\n",
      "3 cores requested.\n",
      "computational jobs per core = 2133. For short computations, each core must have at least 20 jobs to warrant parallel computation.\n",
      "Computations are not lengthy.\n",
      "Rank 0 starting computing on 3 cores (requested 3 cores)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\PycharmProjects\\pyUSID\\pyUSID\\processing\\process.py:760: FutureWarning: Please call this function either as pyUSID.processing.comp_utils.parallel_compute() or simply as pyUSID.parallel_compute() instead in the future\n",
      "  'pyUSID.parallel_compute() instead in the future', FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 0 finished parallel computation\n",
      "Rank 0 - computed chunk in 17.57 sec or 702.8 msec per pixel. Average: 702.8 msec per pixel.\n",
      "Rank: 0 - now holding onto raw data + results has 1.16 GB free memory\n",
      "Strategy to use for reformatting results: \"complex_gaussian\"\n",
      "Raw results and compound SHO vector of shape 6400\n",
      "Reformatting results from the SHO Guess algorithm\n",
      "Prepared guess of shape (6400, 1) before reshaping\n",
      "Reshaped guess to shape (25, 256)\n",
      "Writing data of shape: (25, 256) and dtype: [('Amplitude [V]', '<f4'), ('Frequency [Hz]', '<f4'), ('Quality Factor', '<f4'), ('Phase [rad]', '<f4'), ('R2 Criterion', '<f4')] to positions: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24] in HDF5 dataset:<HDF5 dataset \"Guess\": shape (25, 256), type \"|V20\">\n",
      "located at: \n",
      "\t/Measurement_000/Channel_000/Raw_Data-SHO_Fit_001/Guess \n",
      "Data contains: \n",
      "\tSHO (compound) \n",
      "Data dimensions and original shape: \n",
      "Position Dimensions: \n",
      "\tX - size: 5 \n",
      "\tY - size: 5 \n",
      "Spectroscopic Dimensions: \n",
      "\tDC_Offset - size: 64 \n",
      "\tField - size: 2 \n",
      "\tCycle - size: 2\n",
      "Data Fields:\n",
      "\tAmplitude [V], Phase [rad], Quality Factor, R2 Criterion, Frequency [Hz]:\n",
      "Rank 0 - wrote its 25 pixel chunk in 50.0 msec\n",
      "Rank 0 - 100% complete. Time remaining: 0.0 msec\n",
      "Rank 0 - Finished reading all data!\n",
      "Rank 0 - Finished computing all jobs!\n",
      "Finished processing the entire dataset!\n"
     ]
    }
   ],
   "source": [
    "proc = BESHOfitter(h5_main, verbose=True)\n",
    "proc.set_up_guess()\n",
    "h5_guess = proc.do_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicates:\n",
      "Note: SHO_Fit has already been performed with the same parameters before. These results will be returned by compute() by default. Set override to True to force fresh computation\n",
      "[<HDF5 group \"/Measurement_000/Channel_000/Raw_Data-SHO_Fit_001\" (6 members)>]\n",
      "Checking on partial / completed fit datasets\n",
      "Completed results groups:\n",
      "[<HDF5 group \"/Measurement_000/Channel_000/Raw_Data-SHO_Fit_001\" (6 members)>]\n",
      "Partial results groups:\n",
      "[]\n",
      "Name of status dataset: completed_fit_positions\n",
      "Parameters dictionary: {'algorithm': 'least_squares', 'SHO_fit_method': 'pycroscopy BESHO'}\n",
      "Current results dataset: <HDF5 group \"/Measurement_000/Channel_000/Raw_Data-SHO_Fit_001\" (6 members)>\n"
     ]
    }
   ],
   "source": [
    "proc.set_up_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned previously computed results at /Measurement_000/Channel_000/Raw_Data-SHO_Fit_001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suhas\\PycharmProjects\\pyUSID\\pyUSID\\io\\usi_data.py:148: UserWarning: This dataset does not have an N-dimensional form\n",
      "  warn('This dataset does not have an N-dimensional form')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"Fit\": shape (25, 256), type \"|V20\">\n",
       "located at: \n",
       "\t/Measurement_000/Channel_000/Raw_Data-SHO_Fit_001/Fit \n",
       "Data contains: \n",
       "\tSHO (compound) \n",
       "Data dimensions and original shape: \n",
       "Position Dimensions: \n",
       "\tX - size: 5 \n",
       "\tY - size: 5 \n",
       "Spectroscopic Dimensions: \n",
       "\tDC_Offset - size: 64 \n",
       "\tField - size: 2 \n",
       "\tCycle - size: 2\n",
       "Data Fields:\n",
       "\tAmplitude [V], Phase [rad], Quality Factor, R2 Criterion, Frequency [Hz]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.do_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usid.hdf_utils.print_tree(h5_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.do_guess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
